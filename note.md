# 数値がどのような形式で表現されるか

バイトオーダー
- ビッグエンディアン vs. リトルエンディアン
- 0x123456 という数値のメモリへの格納方法
  - ビッグ: (アドレス小) 12 34 56 (アドレス大)
  - リトル: (アドレス小) 56 34 12 (アドレス大)
- 名前の元ネタは『ガリバー旅行記』
- マシンのエンディアンを確かめる: [byte_order.c](./02/byte_order.c)

文字は ascii コード
  - `man ascii` で表を見られる

符号付き vs. 符号なし整数
- 符号付き整数は 2 の補数: [sign.c](./02/sign.c)

オーバフローの検出
- `s = x + y` とする
- 符号なし加算: `s < x`
- 符号付き加算: `x > 0` かつ `y > 0` かつ `s < 0` or `x < 0` かつ `y < 0` かつ `s > 0`

乗算をシフトと加算に置き換える方法
- `15 * x` -> `(x << 3) + (x << 2) + (x << 1) + x`
- `15 * x` -> `(x << 4) - x`

浮動小数点のフォーマット
- $$(-1)^s * M * 2^E$$
- float (32bit) の場合
  - 0 (s 1bit) 0...0 (e 8bit) 0...0 (m 23bit)
- 正規化数
  - M: 1.m1 m2 m3...
  - E: -127 + e
- 非正規化数 = e が全て 0 の場合
  - M: 0.m1 m2 m3...
  - E: -126
- 特殊な数 = 指数フィールドが全て 1 の場合
  - 正の無限大: s = 0, 小数フィールドが全て 0
  - 負の無限大: s = 1, 小数フィールドが全て 0
  - NaN: 小数フィールドが 0 ではない

浮動小数点フォーマットの意図
- 非正規化数と正規化数が等間隔につながる
  - $$2^{-126} * 2^{-M_n}$$
- ビット表現が符号なし整数と同じ順序になる
  - (最小) 0...00, 0...01, ... 01...1 (最大)

整数から浮動小数点への変換方法
- 整数を 2 進数表記にする
- 1.xxx という形式になるように右シフト
- 小数部はそのまま, シフト数を指数部で表す
- 具体例: 12345
  - 12345 (10) -> 11000000111001 (2)
  - 11000000111001 >> 13 = 1.1000000111001
  - 小数部 = 0...0 1000000111001 (23 bit)
  - 指数部 = 13 + 127 = 140 = 10001100 (2)
  - 結果: 0 10001100 10000001110010000000000
  - 検証: [float.c](./02/float.c)
- Q. 32bit 浮動小数点で誤差なく表せない最小の整数は?
  - A. 2 進数 で 1 0...0 (23 bit) 1 の数 = 2^24+1 = 16777217
  - double は 52bit の小数部を持つので int (32bit) の全ての値を誤差なく表せる

丸め
- 表せる数値のうち最も近い数値
- もし候補が 2 つあるなら偶数の方に丸める
- 丸めによってデータセットに大小の偏りが出ないようにするため

# アセンブリ

C, アセンブリ, 実行可能ファイル
- `gcc -Og -S file.c` によって file.s が出力される
  - -Og: ある程度最適化をしつつデバッグ情報を残す
- `objdump -d a.out` で a.out をディスアセンブルできる
  - a.out の .text セクションをディスアセンブルする (後に詳述)

演算
- データ移動
  - mov
  - スタックの操作: push/pop
- 算術演算
  - add/sub/mul/div/inc/dec
  - 左シフト: sal/shl
  - 右シフト: 算術シフト (符号拡張) sar / 論理シフト (0 埋め) shr
- 浮動小数点
  - %xmm レジスタ (128 bit), %ymm (256 bit)
  - 1 つのレジスタに複数の浮動小数点をパックすることで一度に演算を適用可能
  - 浮動小数点用の命令を用いる (vmovaps など)

制御
- 計算ごとに条件コードレジスタが更新される
  - CF: 最上位ビットからのキャリーが発生したかどうか
  - ZF: 0 かどうか
  - SF: 負の値かどうか
  - OF: オーバフローしたかどうか
- 条件コードレジスタを用いた条件ジャンプ
  - je (等しい): ZF
  - jge (符号付き>=): ~(SF ^ OF)
  - jb (符号なし<): CF
  - など, 条件コードを組み合わせて条件を評価することができる
- if/for/while は条件ジャンプを用いて実装される
- switch はジャンプテーブルによって実現される
  - if-elseif よりも効率が良い
  - 検証: [switch.c](./03/switch.c) と [switch.s](./03/switch.s)
    - case 数を増やさないとジャンプテーブルが使われない

関数
- スタックフレームに情報が格納される
- 呼び出し
  - return アドレスを push
  - レジスタを push して退避
  - 引数をレジスタに mov. レジスタに入り切らない場合はスタックに push
  - レジスタに入り切らないローカル変数をスタック領域に格納

配列と構造体
- メモリ上の連続したアドレスに格納される
- 検証: [struct.c](./03/struct.c) と [struct.s](./03/struct.s)
- 共用体 union はメンバがメモリを共有する
- 可変長スタックフレーム
  - 可変長データ用のスタック領域を確保. その領域の始点アドレス **ベースアドレス** を %rbp に保存

gdb
- `gcc -g file.c` でコンパイル後 `gdb a.out` で起動
- レジスタやスタックフレームの情報を得られる

# CPU

演算
- 論理ゲートで組み合わせ回路を作る
- 組み合わせ回路: 入力の組み合わせによって出力が決まる回路

データ保存
- レジスタとランダムアクセスメモリ
- クロックの立ち上がりの瞬間にデータが書き込まれる

機械語の 1 命令を実行するステップを分割
- フェッチ: 命令を読み出してパーズする
- デコード: オペランドをレジスタから load
- 実行: ALU による演算 or メモリ参照のためのアドレッシング解決 or スタックポインタの移動
- メモリ: データをメモリに store or load
- ライトバック: 実行結果をレジスタに store
- PC 更新: PC を次の命令のアドレスに更新する

パイプライン処理
- 各ステージを並行して行うことでパフォーマンスを上げる
- スループット: 一秒あたり何命令実行できるか IPS = Instructions Per Seconds
- 基本となるアイデア
  - K: 組み合わせ回路, R: レジスタ
  - シーケンシャル: K -> R
  - パイプライン化: K1 -> R1 -> K2 -> R2 -> K3 -> R3
  - 処理の途中結果をレジスタに保存して次々と組み合わせ回路に入力を送る
  - クロック周期は `max (K) + R` 以上にしなければならない
    - つまりなるべく均一に処理を分割すると効率的
- 例外的な場合
  - 計算の依存関係: 待つ or クロックを待たず結果を必要としているステージに送る
  - 条件分岐: 分岐の方向を仮定して先に処理を進める. 間違っていたら結果を捨ててやり直し

# プログラムの最適化

コンパイラの最適化を妨げるもの
- メモリエイリアシング: 2 つのポインタが同じアドレスを指すかもしれない
- 関数呼び出し: 副作用があるかもしれない

最適化
- 関数呼び出しを減らす
- メモリアクセスを減らす
- ループアンローリングでパイプライン処理の恩恵を受ける
- 検証: [vec.c](./05/vec.c), [run.sh](./05/run.sh)
  - 工夫を施すことで初期バージョンの 10 倍の高速化

| combine  | Clock/Loop |
| -------- | ---------- |
| combine1 | 8.818028   |
| combine2 | 8.769837   |
| combine3 | 2.377056   |
| combine4 | 1.30874    |
| combine5 | 0.73422    |

プロファイラ
- コンパイル: `gcc -Og -pg file.c`
- 通常通り実行: `./a.out`
- gmon.out のデータ解析 `gprof a.out`
- 関数に掛かった時間や呼び出し経路が分かる

# メモリの階層構造

メモリの種類
- SRAM: レジスタや L1 キャッシュ
- DRAM: メインメモリや VRAM

HDD の容量
- プラッタ: ディスクのこと
- サーフェス: プラッタの裏面と表面
- トラック: スピンドルから同心円状に配置される
  - セクタ: ビットを保存するユニット
  - ギャップ: データ保存不可. メタデータを保持
- 全容量 = プラッタ数 * サーフェス数 * トラック数 * セクタ数 * 容量

読み出し時の HDD の動作
- シーク: ヘッドを対象セクタのトラックへ合わせる
- 最初のビットがヘッドの下を通過するのを待つ
- アクセスタイムの見積もり: シークタイムの 2 倍

ディスクへの CPU のアクセス
- アドレスを指定して読み込み要求
- ディクスからメインメモリに DMA 転送 (Direct Memory Access)
- DMA 転送が終了したら CPU に割り込み通知

大まかな速度比の目安
- CPU サイクル: 1
- SRAM: 4
- DRAM: 30
- SSD: 10^5
- HDD: 10^6 ~ 10^7
- ここ数十年で CPU とメインメモリの速度差が広がってきたため, SRAM によるキャッシュが重要性を増している

局所性
- あるデータが参照された後
  - 空間的局所性: メモリ上近い場所にあるデータが参照されやすい
  - 時間的局所性: 短時間のうちに複数回参照されやすい
- 局所性があるとキャッシュの効率が高まる

メモリ階層とキャッシュ
- CPU -> レジスタ -> L1 キャッシュ -> L2 キャッシュ -> L3 キャッシュ -> メインメモリ -> ディスク
- k 層のデバイスは k+1 層に対するキャッシュとして働く
- 複数ワードをまとめた **ブロック** 単位でデータがやり取りされる

キャッシュの仕組み
- 構造
  - キャッシュセット (インデックス)
    - キャッシュライン (タグ)
      - キャッシュブロック
- 物理アドレスをセットインデックス, タグ, ブロックオフセットに分ける
- セットインデックスでキャッシュセット, タグでキャッシュラインを特定
- valid ビットが立っていたらキャッシュヒット. オフセットを考慮してデータを読み出す
- valid ビットが立っていなければキャッシュミス. k+1 層のキャッシュからデータ取得

キャッシュに優しいコード
- 二次元配列は行・列の順でループした方が空間的局所性を発揮できる
- 検証: [array.c](./06/array.c)
  - ストライドの違いが 10000 * 10000 の int 配列で 2.5 倍の速度差を生む

局所性を利用するコーディング指針
- メモリに格納されている順番に従ってシーケンシャルにアクセスする
- 一度リードされたデータを使いまわす
- これ以上の最適化は移植性や可読性を犠牲にすることに注意する

# リンクの仕組み

リンカの役割
- シンボル解決: シンボルの参照をシンボルの定義に対応付ける
- 再配置: シンボルのメモリアドレスを決定し, 参照を修正する

オブジェクトファイル
- 再配置可能オブジェクトファイル
  - cpp (C Pre-Processor)
  - cc (C Compiler)
  - as (Assembler)
- 実行可能オブジェクトファイル
  - リンカ ld
- 共有オブジェクトファイル
- オブジェクトファイルを操作するためのツール
  - ar/strings/strip/nm/size/readelf/objdump/lld

オブジェクトファイルのフォーマット
- Linux では ELF64. `readelf` コマンドで見られる
- セクションという単位に分割されている
  - .text: 機械語コード
  - .rodata: 文字列などの読み取り専用データや switch のジャンプテーブル
  - .data: 初期化されたグローバル変数と static 変数
  - .bss: 未初期化または 0 に初期化されたグローバル変数と static 変数
  - .symtab: シンボルテーブル
  - .debug/.line: デバッグ用情報. `-g` オプション付きでコンパイルしたときのみ存在する
  - など
- .data と .bss が分かれているのはサイズ節約のため

シンボルテーブル
- シンボルの状態: 定義されているかどうか
- シンボルの種類: グローバル or static
- シンボルの位置: セクション, オフセット, サイズ
- これらの情報を使って見つかっていないシンボルの定義を埋めていく

リンカのシンボル解決の優先順位
- 同名のシンボルが定義されていると厄介な状況になる可能性がある
- シンボルの強弱
  - strong: 関数, 初期化されたグローバル変数
  - weak: 初期化されていないグローバル変数
- ルール
  - 同名の strong が存在したらエラー
  - 同名の strong と weak が存在したら strong を選ぶ
  - 同名の weak が存在したら任意の一つを選ぶ

静的ライブラリ
- ライブラリの使用する部分のコードを実行可能ファイルに含める形式
- 例えば libc.a をリンクして printf のみ実行可能ファイルに含める
- `ar rcs libfile.a file1.o file2.o` でライブラリ作成
- `gcc -static main.o ./libfile.a` でリンク
- リンカが処理する順番を考えないとリンクエラー
- 相互参照を含むコードのコンパイル: [main.c](./07/slink/main.c), [Makefile](./07/slink/Makefile)

共有ライブラリ
- 動的リンク: 実行時にライブラリのコードをメモリにロードする
- `gcc -shared -fpic -o libf.so f1.c f2.c`
- プログラムから動的リンクすることも可能
  - `dlopen` / `dlsym` / `dlclose` / `dlerror`
  - 利用例 1: アプリ本体ではなく共有ライブラリのみを配布. 次回起動時に更新
  - 利用例 2: CGI プログラムを fork+execve を使わずに実装
- ポジション非依存コード PIC
  - 共有ライブラリはライブラリのオブジェクトファイルの内容の一部を全プロセスで共有できる
  - 変数: .data と .text の相対位置が一定.  GOT を作成して絶対アドレスを得る
  - 関数: 関数の遅延呼び出しにより動的にアドレスを解決する
- インターポジショニング
  - 関数呼び出しをラップできる (コンパイル時, リンク時, 実行時)

# 例外的な制御フロー

低レイヤーでの例外
- 割り込み (interrupt): IO デバイスからの非同期コールバック
- トラップ (trap): システムコール実行
- フォールト (fault): 回復の可能性があるエラー. ページフォールト (メモリページにデータが存在しない) など
- アボート (abort): 回復不能なエラー. 0 除算エラーなど

コンテキストスイッチとプロセス
- プロセス: 実行されているプログラム
- コンピュータでは複数のプロセスが同時に走る
- 実行中のプログラムを素早く切り替えることであたかも同時に処理が進んでいるように見える (コンテキストスイッチ)
- OS は例外の仕組みを利用して, プロセスのコンテキストスイッチという例外的なフローを実現している

シグナル
- 例外的な制御フローを扱うアプリケーションレベルの仕組み
- カーネルやプロセスがプロセスへ小さなメッセージを送ることができる仕組み
- ペンディング
  - 到着したシグナルはカーネルモードからユーザモードへ切り替わるときに受信される
  - ペンディングシグナル: 受信待ちのシグナル
  - 一種類のシグナルは最大一つしかペンディングできない. それ以上は捨てられる
- ブロッキング
  - プロセスはシグナルを指定して受信しないこともできる
  - ハンドラ実行中のシグナルはブロックされる
- シグナルハンドラのインストール `signal`

非局所ジャンプ
- 関数外にジャンプできる
- `setjmp` / `longjmp`

プロセス関連の便利ツール
- `ps` / `top`
- `strace`: プロセスが起動したシステムコールのトレースを見られる
- `pmap`: プロセスのメモリマップを見られる

# 仮想メモリ

仮想メモリの役割
- プロセスにメモリを独占しているように見せてメモリ管理を簡単化
  - リンカやアセンブラなどシステムの中核的な部分に深く関わる
- 別のプロセスのメモリへのアクセス防止

物理メモリアドレスとの変換
- ページテーブル: 仮想アドレスと物理アドレス変換のための対応表. メモリに保存される
- MMU (メモリ管理ユニット): 仮想アドレスと物理アドレスの変換を担う CPU チップ上のハードウェア
- 流れ
  - CPU が仮想アドレスを MMU に送る
  - MMU が仮想アドレスに対応するページテーブルエントリをメモリに要求
  - メモリがページテーブルエントリを MMU に返す
  - MMU が仮想アドレスとページテーブルエントリを元に物理アドレスを作成し, メインメモリに送る
  - メインメモリが要求されたデータを CPU に渡す

ページテーブル
- TLB: ページテーブルエントリをキャッシュする専用のメモリ. MMU 内に存在する
- 階層構造化による容量削減
  - 仮想アドレス全体分のページテーブルを格納するとなるとメモリを圧迫する
  - そこで, 仮想メモリを分割して統括するテーブルを設ける
  - 多くの場合仮想メモリのほとんどの部分は未割り当てなので大幅にデータ省略可能
- コンテキストスイッチのたびにページテーブルをロードし直すコストが掛かる

メモリマッピング
- 仮想メモリを初期化する時, 仮想アドレスとファイルを対応付ける
- 共有ライブラリは一つの物理メモリ上にあり, 複数プロセスの仮想メモリにマップされる
- fork
  - 子プロセスと親プロセスは別の仮想メモリを持つ
  - しかし fork 直後は多くが共有されているのでメモリ使用量はそれほど増えない
  - 書き込むと新たな領域にコピーされる (Copy on Write)
- `mmap` を用いて `read` なしでファイルの中身をメモリにコピーする: [mmap.c](./09/mmap.c)

メモリの動的割り当て
- フリーブロックの扱い, 計算量, 内部/外部断片化が異なるアルゴリズムが複数考案されている
- 標準の `malloc` / `free` は汎用性重視. 場合によってはアプリに特化したメモリアロケータを実装することもありうる.

# ファイル

ファイルとは
- バイト列
- ストレージを始めキーボードやディスプレイなど様々な IO がファイルとして抽象化されている

カーネルによるオープン中のファイル管理
- 3 つのテーブル
  - ファイルディスクリプタテーブル
  - オープンファイルテーブル
  - v- ノードテーブル

# ソケット

```
(both) getaddrinfo -> socket
(server) -> bind -> listen -> accept
(client) -------------------> connect
```

流れ
- `connect` で自動的に **エフェメラルポート** が割り当てられる
- `socket` によって作成された fd はクライアント用がデフォルト
- `listen` によって fd がサーバ用であることをカーネルに伝える

ホスト情報を得る
- `getaddrinfo`: ホスト情報 -> `struct addrinfo`
- `getnameinfo`: `struct addrinfo` -> ホスト情報
- ホスト名を指定して `addrinfo` 取得して直接ソケット関数に渡す
- 特定の IP のバージョンに依存しないコードを書くことが可能

CGI (Common Gateway Interface)
- Web サーバが動的にコンテンツを生成するときのデファクトな方法
- `GET /cgr-bin/func?123&456 HTTP/1.1` のリクエスト
  - `./cgi-bin/func` を起動
  - 引数 `123&456` を環境変数 `QUERY_STRING` で渡す
- 典型的な例
  - `fork()` して子プロセスの中でプログラム実行
  - `setenv("QUERY_STRING", args, overwirte)`
    - 親プロセスの環境変数には影響を与えない
  - `execve(filename, empty_list, environ)`

# 並行プログラミング

プロセスによる並行サーバ
- 接続要求をメインプロセスが受ける, `fork` して子プロセスで処理を行う
- ❌プロセス間で情報を共有するのが難しい
- ❌コンテキストスイッチのコストが掛かる

IO マルチプレクシング (多重化)
- 複数の fd を監視したい場合に使う
  - `select` で読み書き可能になるまで監視する
  - 複数の fd を監視できるので multiplexing
- non-blocking IO と合わせて利用されることもある
  - 毎回 `read` や `write` システムコールで読み書き可否を判定するのはコストが高い
- イベント駆動方式
  - 何らかのイベントに応じて状態を変える方式
  - fd 監視 (状態) -> fd が読み込み可能になる (イベント) -> 処理 -> fd 監視 (状態)
- ⭕シングルプロセスだと情報共有が簡単
- ⭕コンテキストスイッチのコストがない
- ⭕GDB などでデバッグしやすい
- ❌1 ループ内の処理が素早く済むように分割する必要があるためコードが複雑化しやすい
- ❌マルチコアを活用できない

スレッドによる並行サーバ
- メインスレッドとピアスレッド
- スレッドは仮想メモリを共有する
  - スタックやヒープはそれぞれ領域が確保されるが, 別スレッドの領域にアクセスすることもできてしまう
    - 検証: [thread_share.c](./12/thread_share.c)
- 競合状態は排他制御で回避 ([semaphore.c](./12/semaphore.c))
- ❌スレッド作成にコストが掛かる
- ⭕プロセスよりは軽量

並行処理のモデル
- 生産者 - 消費者: 生産者はバッファに push, 消費者はバッファから pop
  - 事前スレッド化サーバ
    - リクエストごとにスレッドを作成するのではなく最初にまとめて作成したスレッドを使いまわす
    - スレッドセーフなキューを用いる実装
    - プロセス版のプリフォークサーバもある
- readers-writer: 読み書きの排他制御

並行処理のコツ
- クリティカルセクションを最小に抑える
- ロックの回数を減らす
- スレッドセーフな関数を利用する
  - リエントラント性: 共有データを参照しない性質
